# **Multimodal RAG-Based Food Recommendation System**

A production-style, portfolio-ready implementation of a **Multimodal Retrieval-Augmented Generation (RAG)** recommender that understands **text + images** to deliver **personalized, context-aware food recommendations** for a restaurant aggregator use-case.

---

## ğŸ§  Overview

Traditional recommenders depend only on text. This project augments retrieval with **visual semantics** using Amazon Bedrock models and stores dense vectors in **FAISS** for sub-second similarity search. The **Streamlit** app provides an interactive chat experience that accepts **text or image queries** and returns grounded recommendations.

---

## ğŸ—ï¸ Architecture
<img width="485" height="375" alt="architecture_diagram" src="https://github.com/user-attachments/assets/8e5b810a-4f8d-4ba8-a350-bb58e2029ab2" />


**Flow (high-level)**

1. **Amazon S3** holds menu images + metadata (CSV).  
2. **Claude Sonnet (Multimodal)** summarizes images (captions, attributes).  
3. **Titan Text Embeddings v2** encodes text/image summaries â†’ vectors.  
4. **FAISS** stores and retrieves vectors (ANN search).  
5. **Streamlit** UI sends user query (text/image) â†’ retrieves top-K â†’  
   **Claude Sonnet** crafts conversational, grounded recommendations.

---

## ğŸ¯ Objectives

- Build a **multimodal** RAG pipeline (text + images).  
- Use **AWS Bedrock** for summarization and embeddings.  
- Store & serve vectors with **FAISS**.  
- Deliver an **interactive Streamlit** experience for search & recommendations.

---

## âœ¨ Features

- Text and image query support (multimodal input).  
- Bedrock-powered summarization and embeddings.  
- Fast vector search with FAISS (local).  
- Clean, minimal **Streamlit** UI with chat-style responses.  
- Easily portable to S3/EC2 for cloud deployment.

---

## âš™ï¸ Tech Stack

- **Language:** Python `3.10.4`  
- **Libraries:** `boto3`, `awscli`, `pandas`, `faiss-cpu`, `langchain`, `langchain-community`, `streamlit`, `streamlit-chat`  
- **Models (Bedrock):**  
  - **Claude Sonnet (Multimodal)** â€” image reasoning & response generation  
  - **Titan Text Embeddings v2** â€” dense vector embeddings  
- **Storage:** Amazon **S3**  
- **Vector DB:** **FAISS** (CPU)  
- **UI:** **Streamlit**

---

## ğŸ§© Data

- **CSV metadata:** menu names, cuisines, nutrition, dietary tags, image paths, ratings, price, etc.  
- **Images folder:** dish/restaurant images aligned with CSV rows.

> You can store the data in **S3** or load it locally during development.

---

## ğŸ“¦ Project Structure

```bash
â”œâ”€ app.py                          # Streamlit app (UI + orchestration)
â”œâ”€ utils.py                        # Helper functions (I/O, encode, retrieve)
â”œâ”€ data/
â”‚  â”œâ”€ images/                      # Menu images
â”‚  â”œâ”€ menu_descriptions_data.csv   # Generated/cleaned captions/descriptions
â”‚  â””â”€ restaurants_menu_data.csv    # Raw menu metadata
â”œâ”€ output/
â”‚  â””â”€ faiss_index/                 # Persisted FAISS index (built at setup)
â”œâ”€ multimodal-llm.ipynb            # Notebook (experiments / quick tests)
â”œâ”€ Multimodal RAG Presentation.pdf # Slides for overview
â”œâ”€ reference-images/               # Support images for README/app
â”œâ”€ requirements.txt
â””â”€ README.md

---

### **For macOS / Linux**
```bash
cd /path/to/project
python3.10 -m venv myenv
source myenv/bin/activate
pip install -r requirements.txt
